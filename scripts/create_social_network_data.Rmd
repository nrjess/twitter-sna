---
title: "Creating Social Network Datasets"
author: "Nicole Jess, Yuqing Liu"
date: "`r format(Sys.time(), '%Y-%m-%d, %H:%M:%S %Z')`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding:  show
params: 
  outfile: "create-social-network-data.html"
---

# Purpose
This script restructures data scraped from Twitter into a format that can be used 
for social network analysis.

```{r global-options, include=FALSE}
# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", paste0("\n \\", options$cfsize,"\n\n", 
                                              x, "\n\n \\normalsize"), x)
  })

# Global chunk options (over-ridden by local chunk options)
knitr::opts_chunk$set(include  = TRUE, echo = TRUE, error = TRUE, 
                      message = FALSE, warning = FALSE, 
                      cfsize = "footnotesize", fig.height=8)

# Declare location of this script relative to the project root directory.
here::i_am(path = "scripts/create_social_network_data.Rmd")
```

# Load R Packages
Load contributed R packages that we need to get additional functions. 

``` {r load-packages}
library(tidyverse)          # dplyr, ggplot2, tidyr, etc.
library(here)               # for here()
library(linkcomm)           # for integer.edgelist()
library(igraph)             # for graph_from_data_frame()

```

# Load data
This loads the data pulled from Twitter in this script: [pull_tweets.RMD](https://github.com/nrjess/twitter-sna/blob/main/scripts/pull_tweets.Rmd) 
script.

``` {r load-data}
# Data files created by "scripts/pull_tweets.Rmd"

load(file=here("data/all_tweets.RData"))

```

# Set up authentication
Authentication is set up using the bearer token that was saved in your .Renviron 
file in the process described on our [README page](https://github.com/nrjess/twitter-sna/tree/main?tab=readme-ov-file#access-to-twitter-data).

```{r auth}

headers = c(`Authorization` = sprintf('Bearer %s', Sys.getenv("TWITTER_BEARER")))

```

# Edgelist
Interaction information is extracted from the Tweet data and restructured into 
an edgelist.

```{r edges}

edgelist <- all_tweets %>%
  unnest(entities) %>%
  unnest_longer(mentions) %>%
  mutate(to=mentions$id) %>%
  rename(tweet_id=id,
         from=author_id) %>%
  drop_na(to,from) %>%
  select(tweet_id, created_at, from, to, text)

```

Altogether, this gives us a total of `r nrow(edgelist)` edges in this network. 

# Integer edgelist

Some social network tools we work with require that the edge IDs are integers 
starting with 1. This code creates an edgelist that meets these requirements.

```{r integer-edges}

# integer edgelist
network1 <- edgelist %>%
  select(from,to) %>%
  as.matrix() %>%
  integer.edgelist()

int_edges <- network1$edges %>%
  as.data.frame() %>%
  rename(from = V1,
         to = V2) %>%
  group_by(from,to) %>%
  summarize(weight = n()) %>%
  as.data.frame()

# save indegree and outdegree to use as node attributes
indegree <- int_edges %>%
  group_by(to) %>%
  summarize(indegree=n()) %>%
  as.data.frame()

outdegree <- int_edges %>%
  group_by(from) %>%
  summarize(outdegree=n()) %>%
  as.data.frame()

```


# Nodelist

This code creates a list of all the nodes in the network and pulls information from 
those Twitter user profiles. 

```{r profile-scrape}

ids <- c(edgelist$from, edgelist$to) %>% unique()

#ids <- paste(ids, collapse = ',') # doesn't work when n>100 (user rate limit is 100)
                                   # but I think we should be able to go up to 500 (rate limit for apps)

#You can do application-only authentication using your apps consumer API keys, or by using a App only Access Token (Bearer Token). 

###############
# workaround - split into chunks and run one chunk every 24 hours
ids <- split(ids, ceiling(seq_along(ids)/100)) # split ids into chunks of length 100
ids <- paste(ids$`1`, collapse = ',') # we can run one chunk every 24 hours
###############

params_users <- list(`ids` = ids,
                     `user.fields` = 'created_at,description,entities,id,location,name,public_metrics,username,verified')

users <- httr::GET('https://api.twitter.com/2/users',
                   httr::add_headers(.headers=headers),
                   query = params_users)

users_data <- httr::content(users,
                            as = 'parsed',
                            type = 'application/json',
                            simplifyDataFrame = TRUE)

nodelist <- users_data %>%
  pluck("data") %>%
  mutate(follower_count=public_metrics$followers_count) %>%
  select(id, username, name, description, created_at, verified, follower_count)

# match integer IDs to node attributes
int_nodes <- network1$nodes %>%
  as.data.frame() %>%
  rename(nodes = 1) %>%
  mutate(id = rownames(.)) %>%
  left_join(nodelist, by="id") %>%
  left_join(indegree, by=c("nodes"="to")) %>%
  left_join(outdegree, by=c("nodes"="from")) %>%
  mutate_at(vars(c(indegree,outdegree)), ~replace(., is.na(.), 0)) %>%
  mutate(degree = indegree + outdegree)


```



# Save Data

```{r save-t2-data}
# here() creates a path relative to the location of the twitter-sna.proj file
# that will be portable across local repositories on different computers.

save(edgelist, file=here("data/edgelist.RData"))
save(nodelist, file=here("data/nodelist.RData"))
save(int_edges, file=here("data/int_edges.RData"))
save(int_nodes, file=here("data/int_nodes.RData"))

```
